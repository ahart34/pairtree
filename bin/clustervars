#!/usr/bin/env python3
import argparse
import numpy as np
import json
import multiprocessing

import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'lib'))
import inputparser
import common
import cluster_pairwise
import cluster_linfreq

def _convert_assignment_to_clustering(Z, vids):
  uniq_Z  = set(list(Z))
  assert uniq_Z == set(range(len(uniq_Z)))
  clusters = [[vids[vidx] for vidx in np.flatnonzero(Z == cidx)] for cidx in sorted(uniq_Z)]
  return clusters

def _make_init_clusters(variants):
  vids = common.extract_vids(variants)
  clusters = [[vid] for vid in vids]
  return clusters

def _select_best(clusterings, llhs):
  best = np.argmax(llhs)
  return clusterings[best]

def _make_unique(clusterings, llhs):
  uniq_clust, idxs = np.unique(clusterings, return_index=True, axis=0)
  uniq_llhs = llhs[idxs]
  return (uniq_clust, uniq_llhs)

def _sort_clusters(clusters, variants):
  vids, V, T, T_prime, omega = inputparser.load_read_counts(variants)
  assert set(vids) == set([vid for clust in clusters for vid in clust])
  vidmap = {vid: idx for idx, vid in enumerate(vids)}

  phi_hat = []
  for C in clusters:
    vidxs = [vidmap[vid] for vid in C]
    phi_hat.append(np.sum(V[vidxs], axis=0) / np.sum(T_prime[vidxs], axis=0))
  phi_hat = np.array(phi_hat)

  K, S = phi_hat.shape
  phi_hat_mean = np.sum(phi_hat, axis=1) / S
  order = np.argsort(-phi_hat_mean)

  sorted_clusters = [clusters[idx] for idx in order]
  return sorted_clusters

def _make_coclust_logprior(prior, variants, scale_prior_with_samps=True):
  assert 0 < prior <= 1
  logprior = np.log(prior)
  if scale_prior_with_samps:
    S = len(list(variants.values())[0]['var_reads'])
    logprior *= S
  return logprior

def main():
  parser = argparse.ArgumentParser(
    description='LOL HI THERE',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter
  )
  parser.add_argument('--concentration', type=float, default=1e-2,
    help='Alpha for Chinese restaurant process. The larger this is, the stronger the preference for more clusters.')
  parser.add_argument('--iterations', type=int, default=100,
    help='Number of Gibbs sampling iterations')
  parser.add_argument('--parallel', dest='parallel', type=int, default=None,
    help='Number of tasks to run in parallel. By default, this is set to the number of CPU cores on the system. On hyperthreaded systems, this will be twice the number of physical CPUs.')
  parser.add_argument('--prior', type=float, default=0.25,
    help='Pairwise coclustering prior probability. Used only for --model=pairwise or --model=both.')
  parser.add_argument('--init-from-existing', action='store_true',
    help='Initialize clusters from those already provided in `in_params_fn`')
  parser.add_argument('--model', choices=('pairwise', 'linfreq', 'both'), default='linfreq',
    help='Clustering model to use')
  parser.add_argument('ssm_fn')
  parser.add_argument('in_params_fn')
  parser.add_argument('out_params_fn')
  args = parser.parse_args()

  np.set_printoptions(linewidth=400, precision=3, threshold=sys.maxsize, suppress=True)
  np.seterr(divide='raise', invalid='raise', over='raise')
  parallel = args.parallel if args.parallel is not None else multiprocessing.cpu_count()

  variants = inputparser.load_ssms(args.ssm_fn)
  orig_params = inputparser.load_params(args.in_params_fn)

  garbage = orig_params.get('garbage', [])
  variants = inputparser.remove_garbage(variants, garbage)

  if args.init_from_existing:
    assert 'clusters' in orig_params
    init_clusters = orig_params['clusters']
  else:
    init_clusters = _make_init_clusters(variants)

  if args.model == 'pairwise':
    coclust_logprior = _make_coclust_logprior(args.prior, variants)
    vids, assigns, llhs = cluster_pairwise.cluster(variants, init_clusters, args.concentration, args.iterations, coclust_logprior, parallel)
  elif args.model == 'linfreq':
    vids, assigns, llhs = cluster_linfreq.cluster(variants, init_clusters, args.concentration, args.iterations)
  elif args.model == 'both':
    raise Exception('Not yet implemented')
  else:
    raise Exception('Unknown --model: %s' % args.model)

  assigns, llhs = _make_unique(assigns, llhs)
  best_assign = _select_best(assigns, llhs)
  clusters = _convert_assignment_to_clustering(best_assign, vids)
  clusters = _sort_clusters(clusters, variants)

  # We expect `samples` will be specified.
  assert 'samples' in orig_params
  params = {
    'clusters': clusters,
    'garbage': garbage,
    'samples': orig_params['samples'],
  }
  with open(args.out_params_fn, 'w') as F:
    json.dump(params, F)

if __name__ == '__main__':
  main()
